{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import helper_functions as hp\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes_mov = {'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'}\n",
    "dtypes_ans={'userId': 'int32','movieId': 'int32','rating': 'float32','timestamp':'int32'\n",
    "            }\n",
    "\n",
    "\n",
    "select_cols_from_movies=['movieId','title','directedBy','starring','genres']\n",
    "select_cols_from_answers=['userId','movieId','rating','predictedRating','timestamp','s5','s6','s7']\n",
    "selec_cols_from_ratings=['userId','movieId','rating']\n",
    "\n",
    "# drop_columns=['s1','s2','s3','s4','s_ser_rel','s_ser_find','s_ser_imp','s_ser_rec'\n",
    "#               ,'m_ser_rel','m_ser_find''m_ser_imp','m_ser_rec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.read_csv(os.getcwd()+'/serendipity-sac2018/movies.csv',\n",
    "                   error_bad_lines=False,usecols=select_cols_from_movies,dtype=dtypes_mov)\n",
    "answers=pd.read_csv(os.getcwd()+'/serendipity-sac2018/answers.csv',\n",
    "                    error_bad_lines=False,usecols=select_cols_from_answers,dtype=dtypes_ans)\n",
    "ratings=pd.read_csv(os.getcwd()+'/ml-latest-small/ratings.csv',dtype=dtypes_mov,usecols=selec_cols_from_ratings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answers[answers.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records 2150 unique users 481 movies 1678\n"
     ]
    }
   ],
   "source": [
    "print('records',len(answers),'unique users',answers.userId.nunique(),'movies',answers.movieId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>predictedRating</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [userId, movieId, rating, timestamp, predictedRating, s5, s6, s7]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[answers.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "records 2048 unique users 471 movies 1602\n"
     ]
    }
   ],
   "source": [
    "print('records',len(answers),'unique users',answers.userId.nunique(),'movies',answers.movieId.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column serendipity score \n",
    "answers['S_{i,u}']=1/3*((answers.s5)+answers.s6 + answers.s7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2=answers[['userId','movieId','rating']]\n",
    "#concat ratings\n",
    "ratings=pd.concat([ratings,ratings2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10309"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=answers[['userId','movieId','S_{i,u}','rating','predictedRating']]\n",
    "popularity=-np.log10((ratings.groupby(['movieId'],as_index=False).size()/ratings.userId.nunique()))\n",
    "training_set=training_set.join(other=popularity.rename('popularity'),on='movieId',how='inner').sort_index()\n",
    "training_set.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings from ml_small\n",
    "ratings=ratings.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "ratings1=ratings.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ratings = ratings.apply(lambda x: x - x.mean(), axis=1)\n",
    "normalized_ratings = normalized_ratings.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def similarity_matrix(ratings,method='item'):\n",
    "    if(method=='item'):\n",
    "        # Transposing the matrix switches columns and rows\n",
    "       \n",
    "        # Calculate similarity coefficients now\n",
    "        similarity_coefficients = cosine_similarity(ratings.T)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return similarity_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_coeff=similarity_matrix(normalized_ratings)\n",
    "# sim_coeff=pd.DataFrame(index=normalized_ratings.columns,\n",
    "#                                 columns=normalized_ratings.columns, \n",
    "#                                 data=sim_coeff)\n",
    "\n",
    "sim_coeff=similarity_matrix(ratings1)\n",
    "sim_coeff=pd.DataFrame(index=ratings1.columns,\n",
    "                                columns=ratings1.columns, \n",
    "                                data=sim_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkIt(seq, num):\n",
    "    avg = len(seq) / float(num)\n",
    "    out = []\n",
    "    last = 1.0\n",
    "\n",
    "    while last < len(seq):\n",
    "        out.append(seq[int(last):int(last + avg)])\n",
    "        last += avg\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,      2,      3, ..., 193585, 193587, 193609])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=10\n",
    "movieId_idx=ratings1.columns.values.copy()\n",
    "np.random.shuffle(movieId_idx)\n",
    "# Create 10 chunks of randomly picked movies\n",
    "I_c=chunkIt(movieId_idx,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>140525</th>\n",
       "      <th>71211</th>\n",
       "      <th>74868</th>\n",
       "      <th>3280</th>\n",
       "      <th>61319</th>\n",
       "      <th>110655</th>\n",
       "      <th>2656</th>\n",
       "      <th>131130</th>\n",
       "      <th>3040</th>\n",
       "      <th>2387</th>\n",
       "      <th>...</th>\n",
       "      <th>3737</th>\n",
       "      <th>2212</th>\n",
       "      <th>31030</th>\n",
       "      <th>8667</th>\n",
       "      <th>1217</th>\n",
       "      <th>144734</th>\n",
       "      <th>31851</th>\n",
       "      <th>82097</th>\n",
       "      <th>2915</th>\n",
       "      <th>7292</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>140525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.46569</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857493</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173463</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71211</td>\n",
       "      <td>0.465690</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.399326</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.44475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048217</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108414</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31851</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2915</td>\n",
       "      <td>0.173463</td>\n",
       "      <td>0.08078</td>\n",
       "      <td>0.048217</td>\n",
       "      <td>0.108414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148743</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369677</td>\n",
       "      <td>0.233695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243813</td>\n",
       "      <td>0.086731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.15178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.231229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151780</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1145 rows × 1145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId    140525   71211     74868     3280    61319     110655   2656    \\\n",
       "movieId                                                                     \n",
       "140525   1.000000  0.46569  0.000000  0.000000     0.0  0.857493  0.00000   \n",
       "71211    0.465690  1.00000  0.000000  0.000000     0.0  0.399326  0.00000   \n",
       "74868    0.000000  0.00000  1.000000  0.000000     0.0  0.000000  0.44475   \n",
       "3280     0.000000  0.00000  0.000000  1.000000     0.0  0.000000  0.00000   \n",
       "61319    0.000000  0.00000  0.000000  0.000000     1.0  0.000000  0.00000   \n",
       "...           ...      ...       ...       ...     ...       ...      ...   \n",
       "144734   0.000000  0.00000  0.000000  0.000000     0.0  0.000000  0.00000   \n",
       "31851    0.000000  0.00000  0.000000  0.000000     0.0  0.000000  0.00000   \n",
       "82097    0.000000  0.00000  0.000000  0.000000     0.0  0.000000  0.00000   \n",
       "2915     0.173463  0.08078  0.048217  0.108414     0.0  0.148743  0.00000   \n",
       "7292     0.000000  0.00000  0.000000  0.000000     0.0  0.000000  0.00000   \n",
       "\n",
       "movieId  131130    3040      2387    ...  3737      2212      31030   8667    \\\n",
       "movieId                              ...                                       \n",
       "140525      0.0  0.000000  0.000000  ...     0.0  0.000000  0.000000     0.0   \n",
       "71211       0.0  0.000000  0.000000  ...     0.0  0.000000  0.000000     0.0   \n",
       "74868       0.0  0.000000  0.000000  ...     0.0  0.000000  0.000000     0.0   \n",
       "3280        0.0  0.000000  0.000000  ...     0.0  0.000000  0.000000     0.0   \n",
       "61319       0.0  0.000000  0.000000  ...     0.0  0.000000  0.000000     0.0   \n",
       "...         ...       ...       ...  ...     ...       ...       ...     ...   \n",
       "144734      0.0  0.000000  0.000000  ...     0.0  0.000000  0.000000     0.0   \n",
       "31851       1.0  0.000000  0.000000  ...     0.0  0.000000  0.000000     0.0   \n",
       "82097       0.0  0.000000  0.000000  ...     0.0  0.000000  0.000000     0.0   \n",
       "2915        0.0  0.369677  0.233695  ...     0.0  0.243813  0.086731     0.0   \n",
       "7292        0.0  0.000000  0.207267  ...     0.0  0.624695  0.000000     0.0   \n",
       "\n",
       "movieId    1217    144734  31851   82097     2915     7292    \n",
       "movieId                                                       \n",
       "140525   0.000000     0.0     0.0     0.0  0.173463  0.00000  \n",
       "71211    0.000000     0.0     0.0     0.0  0.080780  0.00000  \n",
       "74868    0.000000     0.0     0.0     0.0  0.048217  0.00000  \n",
       "3280     0.000000     0.0     0.0     0.0  0.108414  0.00000  \n",
       "61319    0.000000     0.0     0.0     0.0  0.000000  0.00000  \n",
       "...           ...     ...     ...     ...       ...      ...  \n",
       "144734   0.000000     1.0     0.0     0.0  0.000000  0.00000  \n",
       "31851    0.000000     0.0     1.0     0.0  0.000000  0.00000  \n",
       "82097    0.000000     0.0     0.0     1.0  0.000000  0.00000  \n",
       "2915     0.253192     0.0     0.0     0.0  1.000000  0.15178  \n",
       "7292     0.231229     0.0     0.0     0.0  0.151780  1.00000  \n",
       "\n",
       "[1145 rows x 1145 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_coeff.loc[I_c[0],I_c[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "3114    0.569596\n",
       "780     0.564262\n",
       "480     0.564017\n",
       "260     0.557388\n",
       "356     0.546532\n",
       "364     0.541145\n",
       "1210    0.539858\n",
       "648     0.538913\n",
       "1265    0.534169\n",
       "4306    0.527977\n",
       "Name: 1, dtype: float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.get_similar_movies(target_movie=1 ,similarity_coefficients=sim_coeff,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([6947, 108979, 117444, 136542, 150548], dtype='int64', name='movieId')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.get_rated_movies_by_user(205229,ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['rated_movies']=training_set.apply(lambda x: hp.get_rated_movies_by_user(x.userId,ratings).values,axis=1)\n",
    "\n",
    "training_set['s_[i,j]']=training_set.apply(lambda x:hp.find_s_ij_per_user(x.movieId,list(x.rated_movies),sim_coeff),axis=1)\n",
    "\n",
    "training_set['#_movies_rated']=training_set.apply(lambda x: len(hp.get_rated_movies_by_user(x.userId,ratings)),axis=1)\n",
    "\n",
    "training_set['average_similarity']=training_set.apply(lambda x: hp.average_collaboritive_similarity(x['s_[i,j]']),axis=1)\n",
    "\n",
    "training_set=training_set[training_set['#_movies_rated']>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set['#_movies_rated'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>S_{i,u}</th>\n",
       "      <th>rating</th>\n",
       "      <th>predictedRating</th>\n",
       "      <th>popularity</th>\n",
       "      <th>rated_movies</th>\n",
       "      <th>s_[i,j]</th>\n",
       "      <th>#_movies_rated</th>\n",
       "      <th>average_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>205229</td>\n",
       "      <td>108979</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.882299</td>\n",
       "      <td>2.556704</td>\n",
       "      <td>[6947, 108979, 117444, 136542, 150548]</td>\n",
       "      <td>[0.111905076, 0.99999994, 0.51110125, 0.638876...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.488271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>205229</td>\n",
       "      <td>6947</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.253348</td>\n",
       "      <td>1.465624</td>\n",
       "      <td>[6947, 108979, 117444, 136542, 150548]</td>\n",
       "      <td>[1.0000001, 0.111905076, 0.14012733, 0.1751591...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.305120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>205229</td>\n",
       "      <td>117444</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.922837</td>\n",
       "      <td>2.732796</td>\n",
       "      <td>[6947, 108979, 117444, 136542, 150548]</td>\n",
       "      <td>[0.14012733, 0.51110125, 1.0, 0.8, 0.43542293]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.577330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>205229</td>\n",
       "      <td>150548</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.428912</td>\n",
       "      <td>1.954644</td>\n",
       "      <td>[6947, 108979, 117444, 136542, 150548]</td>\n",
       "      <td>[0.09841072, 0.17947192, 0.43542293, 0.280918,...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.398845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>205229</td>\n",
       "      <td>136542</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.101256</td>\n",
       "      <td>3.033826</td>\n",
       "      <td>[6947, 108979, 117444, 136542, 150548]</td>\n",
       "      <td>[0.17515916, 0.63887656, 0.8, 1.0, 0.280918]</td>\n",
       "      <td>5</td>\n",
       "      <td>0.578991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId   S_{i,u}  rating  predictedRating  popularity  \\\n",
       "0  205229   108979  3.000000     5.0         4.882299    2.556704   \n",
       "1  205229     6947  3.666667     4.0         3.253348    1.465624   \n",
       "2  205229   117444  2.666667     4.0         4.922837    2.732796   \n",
       "3  205229   150548  3.333333     4.0         4.428912    1.954644   \n",
       "4  205229   136542  2.666667     5.0         4.101256    3.033826   \n",
       "\n",
       "                             rated_movies  \\\n",
       "0  [6947, 108979, 117444, 136542, 150548]   \n",
       "1  [6947, 108979, 117444, 136542, 150548]   \n",
       "2  [6947, 108979, 117444, 136542, 150548]   \n",
       "3  [6947, 108979, 117444, 136542, 150548]   \n",
       "4  [6947, 108979, 117444, 136542, 150548]   \n",
       "\n",
       "                                             s_[i,j]  #_movies_rated  \\\n",
       "0  [0.111905076, 0.99999994, 0.51110125, 0.638876...               5   \n",
       "1  [1.0000001, 0.111905076, 0.14012733, 0.1751591...               5   \n",
       "2     [0.14012733, 0.51110125, 1.0, 0.8, 0.43542293]               5   \n",
       "3  [0.09841072, 0.17947192, 0.43542293, 0.280918,...               5   \n",
       "4       [0.17515916, 0.63887656, 0.8, 1.0, 0.280918]               5   \n",
       "\n",
       "   average_similarity  \n",
       "0            0.488271  \n",
       "1            0.305120  \n",
       "2            0.577330  \n",
       "3            0.398845  \n",
       "4            0.578991  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols=['predictedRating','popularity','average_similarity','S_{i,u}']\n",
    "tr=training_set.set_index(['userId','movieId']).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr=tr[use_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature_set1=['popularity','average_similarity']\n",
    "feature_set1=['popularity','average_similarity','predictedRating']\n",
    "target=['S_{i,u}']\n",
    "\n",
    "X=tr[feature_set1]\n",
    "y=tr[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>average_similarity</th>\n",
       "      <th>predictedRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.141731</td>\n",
       "      <td>0.275623</td>\n",
       "      <td>3.090528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.954644</td>\n",
       "      <td>0.388727</td>\n",
       "      <td>4.238861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.079583</td>\n",
       "      <td>0.461445</td>\n",
       "      <td>2.998826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.255674</td>\n",
       "      <td>0.348932</td>\n",
       "      <td>3.207525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.556704</td>\n",
       "      <td>0.416538</td>\n",
       "      <td>3.539778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1966</td>\n",
       "      <td>1.188728</td>\n",
       "      <td>0.333621</td>\n",
       "      <td>3.375117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1967</td>\n",
       "      <td>1.153012</td>\n",
       "      <td>0.364907</td>\n",
       "      <td>4.606653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1968</td>\n",
       "      <td>2.130736</td>\n",
       "      <td>0.370144</td>\n",
       "      <td>3.691895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1969</td>\n",
       "      <td>1.954644</td>\n",
       "      <td>0.290604</td>\n",
       "      <td>4.416975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>1.755072</td>\n",
       "      <td>0.298815</td>\n",
       "      <td>4.309538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1971 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      popularity  average_similarity  predictedRating\n",
       "0       1.141731            0.275623         3.090528\n",
       "1       1.954644            0.388727         4.238861\n",
       "2       2.079583            0.461445         2.998826\n",
       "3       2.255674            0.348932         3.207525\n",
       "4       2.556704            0.416538         3.539778\n",
       "...          ...                 ...              ...\n",
       "1966    1.188728            0.333621         3.375117\n",
       "1967    1.153012            0.364907         4.606653\n",
       "1968    2.130736            0.370144         3.691895\n",
       "1969    1.954644            0.290604         4.416975\n",
       "1970    1.755072            0.298815         4.309538\n",
       "\n",
       "[1971 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_size_userId=training_set.userId.unique()[:int(0.8*training_set.userId.nunique())]\n",
    "# test_size_userId=training_set.userId.unique()[int(0.8*training_set.userId.nunique()):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set=tr.loc[training_size_userId]\n",
    "# test_set=tr.loc[test_size_userId]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "X_train=preprocessing.scale(X_train)\n",
    "\n",
    "X_test=preprocessing.scale(X_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "clfs = []\n",
    "clfs.append(RandomForestRegressor())\n",
    "clfs.append(ExtraTreesRegressor())\n",
    "clfs.append(GradientBoostingRegressor())\n",
    "clfs.append(SVR())\n",
    "clfs.append(LinearSVR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>S_{i,u}</td>     <th>  R-squared:         </th> <td>   0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.624</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 29 Mar 2020</td> <th>  Prob (F-statistic):</th>  <td>0.0492</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:26:01</td>     <th>  Log-Likelihood:    </th> <td> -1307.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1320</td>      <th>  AIC:               </th> <td>   2623.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1316</td>      <th>  BIC:               </th> <td>   2644.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    3.1538</td> <td>    0.018</td> <td>  175.585</td> <td> 0.000</td> <td>    3.119</td> <td>    3.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0688</td> <td>    0.026</td> <td>    2.658</td> <td> 0.008</td> <td>    0.018</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -0.0327</td> <td>    0.026</td> <td>   -1.269</td> <td> 0.205</td> <td>   -0.083</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.0053</td> <td>    0.018</td> <td>    0.293</td> <td> 0.770</td> <td>   -0.030</td> <td>    0.041</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>32.240</td> <th>  Durbin-Watson:     </th> <td>   1.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  28.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.295</td> <th>  Prob(JB):          </th> <td>7.86e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.597</td> <th>  Cond. No.          </th> <td>    2.49</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                S_{i,u}   R-squared:                       0.006\n",
       "Model:                            OLS   Adj. R-squared:                  0.004\n",
       "Method:                 Least Squares   F-statistic:                     2.624\n",
       "Date:                Sun, 29 Mar 2020   Prob (F-statistic):             0.0492\n",
       "Time:                        16:26:01   Log-Likelihood:                -1307.6\n",
       "No. Observations:                1320   AIC:                             2623.\n",
       "Df Residuals:                    1316   BIC:                             2644.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          3.1538      0.018    175.585      0.000       3.119       3.189\n",
       "x1             0.0688      0.026      2.658      0.008       0.018       0.120\n",
       "x2            -0.0327      0.026     -1.269      0.205      -0.083       0.018\n",
       "x3             0.0053      0.018      0.293      0.770      -0.030       0.041\n",
       "==============================================================================\n",
       "Omnibus:                       32.240   Durbin-Watson:                   1.990\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               28.113\n",
       "Skew:                           0.295   Prob(JB):                     7.86e-07\n",
       "Kurtosis:                       2.597   Cond. No.                         2.49\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "ols = sm.OLS(y_train, sm.add_constant(X_train))\n",
    "ols_result = ols.fit()\n",
    "ols_result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=ols_result.predict(sm.add_constant(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.4590291725749533, 'mae': 0.5511595054917354, 'r2_score': 0.004801281605008922}\n"
     ]
    }
   ],
   "source": [
    "error_metrics={}\n",
    "error_metrics['mse']=mse(y_test,y_pred)\n",
    "error_metrics['mae']=mae(y_test,y_pred)\n",
    "error_metrics['r2_score']=r2_score(y_test,y_pred)\n",
    "print(error_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.137524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.115499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.210187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.185567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>3.176382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>646</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.136739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>647</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.197067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>648</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.172927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>649</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.167142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.108283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>651 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_true    y_pred\n",
       "0    4.000000  3.137524\n",
       "1    3.333333  3.115499\n",
       "2    3.666667  3.210187\n",
       "3    2.666667  3.185567\n",
       "4    2.666667  3.176382\n",
       "..        ...       ...\n",
       "646  3.666667  3.136739\n",
       "647  3.000000  3.197067\n",
       "648  3.333333  3.172927\n",
       "649  2.333333  3.167142\n",
       "650  3.666667  3.108283\n",
       "\n",
       "[651 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.hstack((y_test.values,y_pred.reshape(y_test.values.shape))),\n",
    "             columns=['y_true','y_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.4612734831558145, 'mae': 0.5550772703998511, 'r2_score': -6.449849612111258e-05}\n"
     ]
    }
   ],
   "source": [
    "baseline_pred=np.full(y_test.shape,np.average(y_train))\n",
    "error_metrics={}\n",
    "error_metrics['mse']=mse(y_test,baseline_pred)\n",
    "error_metrics['mae']=mae(y_test,baseline_pred)\n",
    "error_metrics['r2_score']=r2_score(y_test,baseline_pred)\n",
    "print(error_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "clfs = []\n",
    "clfs.append(LinearRegression())\n",
    "clfs.append(RandomForestRegressor())\n",
    "clfs.append(ExtraTreesRegressor())\n",
    "clfs.append(GradientBoostingRegressor())\n",
    "clfs.append(SVR())\n",
    "clfs.append(LinearSVR())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.apply(lambda x: 1 if(x['S_{i,u}']>3.5) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test.apply(lambda x: 1 if(x['S_{i,u}']>3.5) else 0,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.discrete.discrete_model import Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit=Logit(y_train,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691955\n",
      "         Iterations 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>  1320</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>  1317</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 29 Mar 2020</td> <th>  Pseudo R-squ.:     </th>  <td>-0.1246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:26:02</td>     <th>  Log-Likelihood:    </th> <td> -913.38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -812.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 1.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.1358</td> <td>    0.080</td> <td>    1.702</td> <td> 0.089</td> <td>   -0.021</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>   -0.0990</td> <td>    0.079</td> <td>   -1.250</td> <td> 0.211</td> <td>   -0.254</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.0364</td> <td>    0.056</td> <td>    0.654</td> <td> 0.513</td> <td>   -0.073</td> <td>    0.146</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                 1320\n",
       "Model:                          Logit   Df Residuals:                     1317\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sun, 29 Mar 2020   Pseudo R-squ.:                 -0.1246\n",
       "Time:                        16:26:02   Log-Likelihood:                -913.38\n",
       "converged:                       True   LL-Null:                       -812.18\n",
       "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.1358      0.080      1.702      0.089      -0.021       0.292\n",
       "x2            -0.0990      0.079     -1.250      0.211      -0.254       0.056\n",
       "x3             0.0364      0.056      0.654      0.513      -0.073       0.146\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance \n",
      "\n",
      "baseline predictor report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.83       458\n",
      "           1       0.00      0.00      0.00       193\n",
      "\n",
      "    accuracy                           0.70       651\n",
      "   macro avg       0.35      0.50      0.41       651\n",
      "weighted avg       0.49      0.70      0.58       651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apostolos/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "baseline_pred=np.zeros(y_test.shape)\n",
    "print('Testing performance \\n')\n",
    "print('baseline predictor'+' report \\n',classification_report(y_test,baseline_pred))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "clfs.append(LogisticRegression(solver='liblinear'))\n",
    "clfs.append(SVC())\n",
    "clfs.append(KNeighborsClassifier(n_neighbors=3))\n",
    "clfs.append(DecisionTreeClassifier(criterion='gini'))\n",
    "clfs.append(RandomForestClassifier(n_estimators=100))\n",
    "clfs.append(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'max_depth': 2, 'criterion': 'entropy'\n",
    "clf=\n",
    "model=clf.fit(X_train,y_train)\n",
    "print('Training.performance \\n')\n",
    "print(str(clf)+' report \\n',classification_report(y_train,model.predict(X_train)))\n",
    "\n",
    "pred=model.predict(X_test)\n",
    "#     display(pd.DataFrame(np.stack([y_test,pred],axis=1),columns=['true','pred'],index=y_test.index))\n",
    "print('Testing performance \\n')\n",
    "print(str(clf)+' report \\n',classification_report(y_test,pred))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.performance \n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82       917\n",
      "           1       0.00      0.00      0.00       403\n",
      "\n",
      "    accuracy                           0.69      1320\n",
      "   macro avg       0.35      0.50      0.41      1320\n",
      "weighted avg       0.48      0.69      0.57      1320\n",
      "\n",
      "Testing performance \n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.83       458\n",
      "           1       0.00      0.00      0.00       193\n",
      "\n",
      "    accuracy                           0.70       651\n",
      "   macro avg       0.35      0.50      0.41       651\n",
      "weighted avg       0.49      0.70      0.58       651\n",
      "\n",
      "Training.performance \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apostolos/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/apostolos/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False) report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82       917\n",
      "           1       1.00      0.00      0.01       403\n",
      "\n",
      "    accuracy                           0.70      1320\n",
      "   macro avg       0.85      0.50      0.42      1320\n",
      "weighted avg       0.79      0.70      0.57      1320\n",
      "\n",
      "Testing performance \n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False) report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.83       458\n",
      "           1       0.00      0.00      0.00       193\n",
      "\n",
      "    accuracy                           0.70       651\n",
      "   macro avg       0.35      0.50      0.41       651\n",
      "weighted avg       0.49      0.70      0.58       651\n",
      "\n",
      "Training.performance \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform') report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       917\n",
      "           1       0.74      0.50      0.59       403\n",
      "\n",
      "    accuracy                           0.79      1320\n",
      "   macro avg       0.77      0.71      0.73      1320\n",
      "weighted avg       0.79      0.79      0.78      1320\n",
      "\n",
      "Testing performance \n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "                     weights='uniform') report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.73       458\n",
      "           1       0.29      0.24      0.27       193\n",
      "\n",
      "    accuracy                           0.60       651\n",
      "   macro avg       0.50      0.50      0.50       651\n",
      "weighted avg       0.58      0.60      0.59       651\n",
      "\n",
      "Training.performance \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       917\n",
      "           1       1.00      1.00      1.00       403\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "Testing performance \n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best') report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       458\n",
      "           1       0.33      0.33      0.33       193\n",
      "\n",
      "    accuracy                           0.60       651\n",
      "   macro avg       0.52      0.52      0.52       651\n",
      "weighted avg       0.60      0.60      0.60       651\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apostolos/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training.performance \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       917\n",
      "           1       1.00      1.00      1.00       403\n",
      "\n",
      "    accuracy                           1.00      1320\n",
      "   macro avg       1.00      1.00      1.00      1320\n",
      "weighted avg       1.00      1.00      1.00      1320\n",
      "\n",
      "Testing performance \n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78       458\n",
      "           1       0.36      0.20      0.26       193\n",
      "\n",
      "    accuracy                           0.66       651\n",
      "   macro avg       0.54      0.53      0.52       651\n",
      "weighted avg       0.61      0.66      0.62       651\n",
      "\n",
      "Training.performance \n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85       917\n",
      "           1       0.98      0.20      0.33       403\n",
      "\n",
      "    accuracy                           0.75      1320\n",
      "   macro avg       0.86      0.60      0.59      1320\n",
      "weighted avg       0.81      0.75      0.69      1320\n",
      "\n",
      "Testing performance \n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False) report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81       458\n",
      "           1       0.30      0.05      0.09       193\n",
      "\n",
      "    accuracy                           0.68       651\n",
      "   macro avg       0.50      0.50      0.45       651\n",
      "weighted avg       0.59      0.68      0.60       651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "for clf in clfs:\n",
    "    model=clf.fit(X_train,y_train)\n",
    "    print('Training.performance \\n')\n",
    "    print(str(clf)+' report \\n',classification_report(y_train,model.predict(X_train)))\n",
    "   \n",
    "    pred=model.predict(X_test)\n",
    "#     display(pd.DataFrame(np.stack([y_test,pred],axis=1),columns=['true','pred'],index=y_test.index))\n",
    "    print('Testing performance \\n')\n",
    "    print(str(clf)+' report \\n',classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apostolos/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_dist = {\"max_depth\": [2, 4, 6, 8, None],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "tree =DecisionTreeClassifier()\n",
    "\n",
    "search=RandomizedSearchCV(tree,param_dist).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'criterion': 'entropy'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
